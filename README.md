# thesis_text_summarization_models_intelligence_community
National Intelligence University Thesis: Deep Learning Text Summarization Models in the U.S. Intelligence Community

Abstract: Machine learning (ML) text summarization models, driven by recent advances in generative artificial intelligence (AI), efficiently reduce emails, reports, and other documents into concise summaries. Analysts in the intelligence community (IC) can benefit from these models, gaining an advantage over adversaries when time is critical. However, there is a lack of contemporary, in-depth IC research on this topic. This study addresses that gap by answering the research question: What are the most effective approaches to high-quality automatic text summarization in the IC? Experiments with pre-trained language models (BART, T5, and Pegasus) and large language models (LLMs) (Llama2 and Llama3) were conducted. Models were tested on the summarization task, and several were fine-tuned with additional training data. Summarization quality was quantitatively scored with the automated metric ROUGE. Llama3 performed qualitative comparisons between model-generated summaries. Limited human evaluation supplemented the research. The studies reveal that Llama2 appears to outperform the smaller pre-trained models in the summarization task. The research also highlights the limitations of the ROUGE metric for measuring summary quality and suggests Llama3 as an effective evaluation tool. Additionally, organizational culture and resource allocation are identified as key enablers for deploying AI/ML solutions at scale. It is hoped that this study will assist IC organizations to understand, import, test, train, deploy, and evaluate state-of-the art text summarization models in mission-critical scenarios.

